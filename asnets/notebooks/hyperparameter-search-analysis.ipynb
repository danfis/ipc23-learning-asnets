{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis for hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'm just going to load exploding blocks data & use that for all my analysis. Later on, I'll move things into functions & execute them separately.\n",
    "\n",
    "Also, why doesn't Jupyter have support for this kind of repeated analysis? It would be nice to have scoped, parameterised cells that could play a similar role to functions, but make it easier to fiddle with values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_data = pd.read_csv('./tune-results-exbw.csv')\n",
    "# prob_data = pd.read_csv('./tune-results-gm.csv')\n",
    "# prob_data = pd.read_csv('./tune-results-mbw.csv')\n",
    "prob_data = pd.read_csv('./tune-results-pbw-exw-huge.csv')\n",
    "# prob_data = pd.read_csv('./tune-results-huge-gm-mbw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rest of this stuff should be problem-agnostic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_cols = [c for c in prob_data.columns if c.startswith('config:')]\n",
    "conf_names = [c.split(':', 1)[1] for c in conf_cols]\n",
    "print('Configuration variables:')\n",
    "for i, (conf_col, conf_name) in enumerate(zip(conf_cols, conf_names)):\n",
    "    print('  [%02d] %s (%s)' % (i, conf_name, conf_col))\n",
    "cov_series = prob_data['coverage'].dropna()\n",
    "print(\"Found %d runs, of which %d have non-NaN coverage\" % (len(prob_data), len(cov_series)))\n",
    "prob_data_with_nans = prob_data\n",
    "prob_data['coverage_clean'] = prob_data['coverage'].fillna(-0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(cov_series, bins=20)\n",
    "plt.title(\"Coverage of successfully completed tuning runs\")\n",
    "plt.xlabel(\"Coverage (fraction of runs reaching goal)\")\n",
    "plt.ylabel(\"Number of trials with coverage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting effect of individual variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot coverage as a function of each var\n",
    "log_scale_vars = {'l1_reg', 'l2_reg'}\n",
    "for ls_var in sorted(log_scale_vars):\n",
    "    prob_data[f'config:{ls_var}_log10'] = prob_data[f'{ls_var}_log10'] = np.log10(prob_data[ls_var])\n",
    "prob_data['success'] = prob_data['coverage'].notnull()\n",
    "plot_cols = 3\n",
    "plot_rows = int(np.ceil(len(conf_names) / float(plot_cols)))\n",
    "plt.figure(figsize=(20, 5 * plot_rows))\n",
    "for plot_num, (conf_name, conf_col_name) in enumerate(zip(conf_names, conf_cols), start=1):\n",
    "    plt.subplot(plot_rows, plot_cols, plot_num)\n",
    "    if conf_name in log_scale_vars:\n",
    "        # this needs to happen before sns.scatterplot() or it will mess up the x-axis range\n",
    "        plt.xscale('log')\n",
    "    sns.scatterplot(x=conf_name, y='coverage_clean', hue='success', data=prob_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting effect of pairs of vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_vars = ['l2_reg_log10', 'dropout', 'hidden_size']  #, 'l1_reg_log10',]\n",
    "pair_col_names = [f'config:{n}' for n in pair_vars]\n",
    "plt.figure(figsize=(20, 30))\n",
    "\n",
    "sns.pairplot(\n",
    "    data=prob_data, hue='coverage_clean', diag_kind='hist', vars=pair_vars,\n",
    "    palette=sns.cubehelix_palette(len(set(prob_data['coverage_clean']))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out what the best configs are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_few = prob_data.nlargest(20, 'coverage_clean')\n",
    "plt.figure(figsize=(20, 5 * plot_rows))\n",
    "for plot_num, (conf_name, conf_col_name) in enumerate(zip(conf_names, conf_cols), start=1):\n",
    "    plt.subplot(plot_rows, plot_cols, plot_num)\n",
    "    if conf_name in log_scale_vars:\n",
    "        plt.xscale('log')\n",
    "    sns.scatterplot(x=conf_name, y='coverage_clean', data=best_few)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_idx in range(len(best_few)):\n",
    "    row_num = row_idx + 1\n",
    "    row = best_few.iloc[row_idx]\n",
    "    print(\"Config #%d (coverage=%f):\" % (row_num, row['coverage_clean']))\n",
    "    for conf_name in conf_names:\n",
    "        print(f\"  {conf_name} = {row[conf_name]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
